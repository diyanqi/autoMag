# path: src/ai_processor.py

import json
import openai
from src import config
from src.prompts import SYSTEM_PROMPT, create_user_prompt, MODERATION_SYSTEM_PROMPT, create_moderation_user_prompt, DESCRIPTION_SYSTEM_PROMPT, create_description_user_prompt
import re

# Import json5 for robust JSON parsing
try:
    import json5
except ImportError:
    json5 = None
    print("ğŸš¨ è­¦å‘Šï¼šjson5åº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ 'pip install json5' ä»¥è·å¾—æ›´å¥å£®çš„JSONè§£æèƒ½åŠ›ã€‚")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
try:
    client = openai.OpenAI(
        api_key=config.OPENAI_API_KEY,
        base_url=config.OPENAI_API_BASE_URL,
    )
except Exception as e:
    raise ImportError(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

def is_article_safe(title: str, content: str) -> bool:
    """
    Checks if an article is safe for distribution.

    Args:
        title: The title of the article.
        content: The content of the article.

    Returns:
        True if the article is safe, False otherwise.
    """
    print(f"ğŸ›¡ï¸  Performing safety check for: {title}")
    user_prompt = create_moderation_user_prompt(title, content)
    try:
        completion = client.chat.completions.create(
            model=config.MODEL_NAME,
            messages=[
                {"role": "system", "content": MODERATION_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.0,
            max_tokens=5,
            extra_body={"chat_template_kwargs": {"thinking":False}},
        )

        message = completion.choices[0].message
        
        # --- å¥å£®æ€§ä¿®å¤ ---
        # åœ¨è°ƒç”¨ .strip() ä¹‹å‰ï¼Œæ£€æŸ¥ message å’Œ message.content æ˜¯å¦å­˜åœ¨
        if message and message.content:
            response = message.content.strip().lower()
            if response == "safe":
                print("âœ… Safety check passed.")
                return True
            else:
                print(f"âŒ Safety check failed. Reason from AI: {response}")
                return False
        else:
            # å¦‚æœAIè¿”å›ç©ºå†…å®¹ï¼Œåˆ™é»˜è®¤ä¸ºä¸å®‰å…¨ï¼Œä¿è¯"å®‰å…¨å¤±è´¥"
            print("âŒ Safety check failed. Reason: AI returned an empty response.")
            return False
        # --- ä¿®å¤ç»“æŸ ---

    except openai.APIError as e:
        print(f"Could not complete safety check due to API error: {e}")
        return False # Fail safe
    except Exception as e:
        # å¢åŠ ä¸€ä¸ªé€šç”¨çš„å¼‚å¸¸æ•è·ï¼Œä»¥é˜²å…¶ä»–æ„å¤–é”™è¯¯
        print(f"An unexpected error occurred during safety check: {e}")
        return False # Fail safe

def generate_material_description(material_data: dict) -> str:
    """
    ä½¿ç”¨AIä¸ºææ–™ç”Ÿæˆè‡ªç„¶ã€å¸å¼•äººçš„æè¿°ã€‚

    Args:
        material_data: å®Œæ•´çš„ææ–™æ•°æ®å­—å…¸

    Returns:
        AIç”Ÿæˆçš„ææ–™æè¿°
    """
    print("ğŸ¨ æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆææ–™æè¿°...")
    
    user_prompt = create_description_user_prompt(material_data)
    
    try:
        completion = client.chat.completions.create(
            model=config.MODEL_NAME,
            messages=[
                {"role": "system", "content": DESCRIPTION_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„æè¿°
            max_tokens=500,   # é™åˆ¶æè¿°é•¿åº¦
            extra_body={"chat_template_kwargs": {"thinking":False}},
        )

        message = completion.choices[0].message
        
        if message and message.content:
            description = message.content.strip()
            print(f"âœ… AIæè¿°ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(description)} å­—ç¬¦")
            return description
        else:
            print("âŒ AIè¿”å›ç©ºæè¿°")
            return ""

    except openai.APIError as e:
        print(f"âŒ AI APIé”™è¯¯: {e}")
        return ""
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæè¿°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return ""

def generate_reading_material(title: str, content: str, url: str) -> dict:
    """
    è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆç²¾è¯»ææ–™ï¼Œä½¿ç”¨æµå¼ä¼ è¾“å¹¶åœ¨ç»ˆç«¯å®æ—¶è¾“å‡ºï¼Œå¹¶è¿›è¡Œå¥å£®çš„JSONè§£æã€‚

    Args:
        title: æ–‡ç« æ ‡é¢˜ã€‚
        content: æ–‡ç« æ­£æ–‡ã€‚

    Returns:
        ä¸€ä¸ªè§£æå¥½çš„Pythonå­—å…¸ã€‚
    """
    print("ğŸ”„ æ­£åœ¨è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆç²¾è¯»å†…å®¹ï¼ˆæµå¼ä¼ è¾“ï¼‰...")
    
    user_prompt = create_user_prompt(title, content, url)
    
    try:
        # åˆ›å»ºæµå¼è¯·æ±‚
        stream = client.chat.completions.create(
            model=config.MODEL_NAME,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.3,
            response_format={"type": "json_object"}, 
            extra_body={"chat_template_kwargs": {"thinking":False}},
            max_tokens=3533000,
            stream=True
        )
        
        print("ğŸ“¡ å¼€å§‹æ¥æ”¶æµå¼å“åº”...")
        print("-" * 50)
        
        raw_response = ""
        
        # å¤„ç†æµå¼å“åº”
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                chunk_content = chunk.choices[0].delta.content
                raw_response += chunk_content
                
                # å®æ—¶è¾“å‡ºåˆ°ç»ˆç«¯
                print(chunk_content, end='', flush=True)
        
        print()
        print("-" * 50)
        print("âœ… æµå¼ä¼ è¾“å®Œæˆ")
        
        # --- é²æ£’æ€§ JSON è§£æå¤„ç† ---
        parsed_json = None
        
        # å°è¯•æ ‡å‡†JSONè§£æ
        try:
            parsed_json = json.loads(raw_response)
            print("âœ… AIå†…å®¹ç”Ÿæˆå®Œæ¯•ï¼Œæ ‡å‡†JSONè§£ææˆåŠŸã€‚")
            return parsed_json
        except json.JSONDecodeError as e:
            print(f"âš ï¸ æ ‡å‡†JSONè§£æå¤±è´¥: {e}ã€‚å°è¯•ä½¿ç”¨æ›´å¥å£®çš„è§£æå™¨...")
            
        # å°è¯•ä½¿ç”¨json5è¿›è¡Œæ›´å¥å£®çš„è§£æ
        if parsed_json is None and json5:
            try:
                parsed_json = json5.loads(raw_response)
                print("âœ… ä½¿ç”¨json5æˆåŠŸè§£æã€‚")
                return parsed_json
            except Exception as json5_e:
                print(f"âŒ json5è§£æå¤±è´¥: {json5_e}")
        elif parsed_json is None and not json5:
            print("ğŸš¨ è­¦å‘Šï¼šjson5åº“æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œæ›´å¥å£®çš„JSONè§£æã€‚")

        # æœ€ç»ˆå°è¯•ï¼šæ‰‹åŠ¨æå–JSONå­—ç¬¦ä¸²å¹¶å†æ¬¡å°è¯•æ ‡å‡†è§£æ
        if parsed_json is None:
            print("âš ï¸ å°è¯•æ‰‹åŠ¨æå–JSONå¯¹è±¡å¹¶è§£æ...")
            try:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥æ›´å‡†ç¡®åœ°æŸ¥æ‰¾å¯èƒ½çš„JSONå¯¹è±¡
                # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼å°è¯•åŒ¹é…ä¸€ä¸ªä»¥'{'å¼€å§‹å¹¶ä»¥'}'ç»“æŸï¼Œå¹¶ä¸”ä¸­é—´å¯èƒ½åŒ…å«ä»»ä½•å­—ç¬¦çš„å­—ç¬¦ä¸²ï¼Œ
                # ä½†å¯¹äºåµŒå¥—ç»“æ„å’Œå¤æ‚é”™è¯¯ä»æœ‰é™ã€‚
                match = re.search(r'\{.*\}', raw_response, re.DOTALL)
                if match:
                    json_str_potential = match.group(0)
                    parsed_json = json.loads(json_str_potential)
                    print("âœ… æ‰‹åŠ¨æå–å¹¶æ ‡å‡†JSONè§£ææˆåŠŸã€‚")
                    return parsed_json
                else:
                    raise ValueError("åœ¨AIå“åº”ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„JSONå¯¹è±¡ç»“æ„ã€‚")
            except (json.JSONDecodeError, ValueError) as e:
                print("âŒ æœ€ç»ˆè§£æå¤±è´¥ã€‚")
                print("--- åŸå§‹å“åº” ---")
                print(raw_response)
                print("-----------------")
                raise ValueError(f"æ— æ³•è§£æAIçš„å“åº”: {e}")

    except openai.APIError as e:
        raise ConnectionError(f"AI APIè¿”å›é”™è¯¯: {e}")
    except Exception as e:
        raise RuntimeError(f"è°ƒç”¨AIæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

def generate_preview_content(material_data: dict) -> dict:
    """
    åŸºäºå®Œæ•´çš„material_dataç”Ÿæˆé¢„è§ˆå†…å®¹ï¼ŒåªåŒ…å«å‰2ä¸ªæ®µè½å’Œéƒ¨åˆ†è¯æ±‡ã€‚
    
    Args:
        material_data: å®Œæ•´çš„ææ–™æ•°æ®å­—å…¸
        
    Returns:
        é¢„è§ˆå†…å®¹çš„å­—å…¸
    """
    try:
        preview_data = {
            "type": material_data.get("type", "foreign_reading"),
            "version": material_data.get("version", "1.0"),
            "source": material_data.get("source", ""),
            "metadata": material_data.get("metadata", {}),
            "content": {
                "title": material_data.get("content", {}).get("title", {}),
                "paragraphs": [],
                "summary": {
                    "english": "Preview available. Full content includes detailed analysis of all paragraphs.",
                    "chinese": "é¢„è§ˆç‰ˆæœ¬ã€‚å®Œæ•´ç‰ˆæœ¬åŒ…å«æ‰€æœ‰æ®µè½çš„è¯¦ç»†åˆ†æã€‚"
                }
            }
        }
        
        original_paragraphs = material_data.get("content", {}).get("paragraphs", [])[:2]
        for paragraph in original_paragraphs:
            preview_paragraph = paragraph.copy()
            if "analysis" in preview_paragraph and "vocabulary" in preview_paragraph["analysis"]:
                preview_paragraph["analysis"]["vocabulary"] = preview_paragraph["analysis"]["vocabulary"][:2]
            if "analysis" in preview_paragraph and "grammar" in preview_paragraph["analysis"]:
                 if "points" in preview_paragraph["analysis"]["grammar"]:
                    preview_paragraph["analysis"]["grammar"]["points"] = preview_paragraph["analysis"]["grammar"]["points"][:1]
            
            preview_data["content"]["paragraphs"].append(preview_paragraph)
        
        preview_data["content"]["preview_note"] = "This is a preview version. Full content contains analysis of all paragraphs with complete vocabulary and grammar explanations."
        
        return preview_data
        
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆé¢„è§ˆå†…å®¹æ—¶å‡ºé”™: {e}")
        return {
            "type": "foreign_reading",
            "version": "1.0",
            "content": {
                "title": material_data.get("content", {}).get("title", {"english": "Preview", "chinese": "é¢„è§ˆ"}),
                "preview_note": "Preview content generation failed. Please check the full content."
            }
        }