import requests
import feedparser
from bs4 import BeautifulSoup

def fetch_new_article_links(feed_url: str) -> list[str]:
    """
    Parses an RSS feed and returns a list of article links.

    Args:
        feed_url: The URL of the RSS feed.

    Returns:
        A list of URLs for the articles in the feed.
    """
    print(f"ğŸ” Checking feed: {feed_url}")
    feed = feedparser.parse(feed_url)
    return [entry.link for entry in feed.entries]


def fetch_article(url: str) -> dict:
    """
    ä»ç»™å®šçš„URLæŠ“å–æ–°é—»æ ‡é¢˜å’Œæ­£æ–‡å†…å®¹ã€‚

    Args:
        url: æ–°é—»æ–‡ç« çš„URLã€‚

    Returns:
        ä¸€ä¸ªåŒ…å«'title'å’Œ'content'çš„å­—å…¸ã€‚
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status() # å¦‚æœè¯·æ±‚å¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸

        soup = BeautifulSoup(response.text, 'html.parser')

        # æå–æ ‡é¢˜
        title_tag = soup.find('h1') or soup.find('title')
        title_text = title_tag.get_text(strip=True) if title_tag else "æ— æ³•æå–æ ‡é¢˜"

        # æå–æ­£æ–‡å†…å®¹ (è¿™æ˜¯ä¸€ä¸ªé€šç”¨å°è¯•ï¼Œå¯èƒ½éœ€è¦ä¸ºç‰¹å®šç½‘ç«™è°ƒæ•´)
        # ä¼˜å…ˆå¯»æ‰¾ <article> æ ‡ç­¾ï¼Œå…¶æ¬¡æ˜¯ <main>
        article_body = soup.find('article') or soup.find('main')
        
        if not article_body:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±é€€è€Œæ±‚å…¶æ¬¡ï¼Œè·å–æ‰€æœ‰ <p> æ ‡ç­¾çš„å†…å®¹
            paragraphs = soup.find_all('p')
        else:
            paragraphs = article_body.find_all('p')

        content_text = ' '.join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])
        
        if not content_text:
             raise ValueError("æ— æ³•ä»é¡µé¢æå–åˆ°æœ‰æ•ˆçš„æ®µè½å†…å®¹ã€‚")

        print(f"âœ… æˆåŠŸæŠ“å–æ–‡ç« : {title_text}")
        # print(content_text)
        return {
            'title': title_text,
            'content': content_text,
            'original_link': url
        }

    except requests.exceptions.RequestException as e:
        raise ConnectionError(f"æŠ“å–æ–‡ç« å¤±è´¥: ç½‘ç»œé”™è¯¯ - {e}")
    except Exception as e:
        raise RuntimeError(f"è§£ææ–‡ç« æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
